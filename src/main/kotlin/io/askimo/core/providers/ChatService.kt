/* SPDX-License-Identifier: Apache-2.0
 *
 * Copyright (c) 2025 Hai Nguyen
 */
package io.askimo.core.providers

import dev.langchain4j.service.TokenStream
import dev.langchain4j.service.UserMessage

/**
 * Defines the contract for services that provide chat functionality with language models.
 *
 * This interface abstracts the underlying implementation details of different language model
 * providers, allowing the application to interact with various chat models through a unified API.
 */
interface ChatService {
    /**
     * Streams the response from a language model for the given prompt.
     *
     * This method provides an asynchronous streaming API that returns tokens as they
     * are generated by the language model.
     *
     * @param prompt The input text to send to the language model
     * @return A [TokenStream] that emits tokens as they are generated
     */
    fun sendMessageStreaming(
        @UserMessage prompt: String,
    ): TokenStream

    /**
     * Sends a simple chat message and returns the complete response.
     *
     * @param prompt The user message to send
     * @return The complete response from the AI
     */
    fun sendMessage(@UserMessage prompt: String): String
}

/**
 * Extension function that sends a chat message and calls the onToken callback for each token.
 *
 * @param prompt The user message to send
 * @param onToken Callback function called for each token as it's generated
 * @return The complete response from the AI
 */
fun ChatService.sendMessageStreaming(prompt: String, onToken: (String) -> Unit = {}): String {
    val result = StringBuilder()
    sendMessageStreaming(prompt)
        .onPartialResponse { token ->
            onToken(token)
            result.append(token)
        }
        .onError { error ->
            throw error
        }
        .start()
    return result.toString()
}
